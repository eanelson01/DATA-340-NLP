{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings (Word2Vec, Sent2Vec, and Doc2Vec)\n",
    "\n",
    "## Due date\n",
    "\n",
    "April 30, 2018\n",
    "\n",
    "## Assignment description\n",
    "\n",
    "In this assignment, you will implement a semantic search engine using the word2vec algorithm. You will use pre-trained word embeddings and build a search engine that can retrieve documents related to a given query based on semantic similarity.\n",
    "\n",
    "### Objective\n",
    "\n",
    "1. Familiarize yourself with the word2vec algorithm: Start by reading about the word2vec algorithm and its applications in NLP. You can use the resources provided in the course or search for additional materials online.\n",
    "\n",
    "2. Choose a pre-trained word embedding model: There are many pre-trained word embedding models available online, such as Google's Word2Vec, Stanford's GloVe, and Facebook's fastText. Choose one that you find suitable for your task and download it. See the lecture notebooks for links to code that can be used to load the models.\n",
    "\n",
    "3. Preprocess the data: Choose a dataset of documents that you want to use for your search engine. Use the news dataset that you performed Exploratory Data Analysis on the previous assignment.\n",
    "\n",
    "4. Map the documents to vectors: Use the pre-trained word embedding model to map the words in each document to vectors. You can do this by averaging the vectors of the individual words in each document or using a more sophisticated technique such as doc2vec.\n",
    "\n",
    "5. Implement the search engine: Given a query, map it to a vector using the same technique you used for the documents. Then, retrieve the documents that are most similar to the query vector based on cosine similarity or another distance metric.\n",
    "\n",
    "6. Write a brief summary of your algorithm and document it's usage with some examples.\n",
    "\n",
    "### Outcomes\n",
    "\n",
    "The student will be able to:\n",
    "\n",
    "1. Implement a semantic search engine using word embeddings.\n",
    "2. Use pre-trained word embedding models.\n",
    "3. Map documents to vectors using word embeddings.\n",
    "4. Discover how cosine similarity can be used to cluster documents.\n",
    "\n",
    "## Submission medium\n",
    "\n",
    "Well documented Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset used in this assignment is the same as the one used in the EDA assignment. That is, the input for this assignment is the output you created in the EDA assignment. You can download the preprocessed dataset from the following link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_source = 'https://raw.githubusercontent.com/JamesMTucker/DATA_340_NLP/master/Notebooks/data/news-2023-02-01.csv'\n",
    "\n",
    "articles = pd.read_csv(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politicususa</td>\n",
       "      <td>Prosecutors Pay Attention: Stormy Daniels Than...</td>\n",
       "      <td>Manhattan prosecutors are likely to notice tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politicususa</td>\n",
       "      <td>Investigators Push For Access To Trump Staff C...</td>\n",
       "      <td>Print\\nInvestigators looking into Donald Trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politicususa</td>\n",
       "      <td>The End Is Near For George Santos As He Steps ...</td>\n",
       "      <td>The AP reported:\\nRepublican Rep. George Santo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politicususa</td>\n",
       "      <td>Rachel Maddow Cuts Trump To The Bone With Stor...</td>\n",
       "      <td>Rachel Maddow showed how Trump committed a cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vox</td>\n",
       "      <td>Alec Baldwin has been formally charged with in...</td>\n",
       "      <td>Candles are placed in front of a photo of cine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         source                                              title  \\\n",
       "0  politicususa  Prosecutors Pay Attention: Stormy Daniels Than...   \n",
       "1  politicususa  Investigators Push For Access To Trump Staff C...   \n",
       "2  politicususa  The End Is Near For George Santos As He Steps ...   \n",
       "3  politicususa  Rachel Maddow Cuts Trump To The Bone With Stor...   \n",
       "4           vox  Alec Baldwin has been formally charged with in...   \n",
       "\n",
       "                                                text  \n",
       "0  Manhattan prosecutors are likely to notice tha...  \n",
       "1  Print\\nInvestigators looking into Donald Trump...  \n",
       "2  The AP reported:\\nRepublican Rep. George Santo...  \n",
       "3  Rachel Maddow showed how Trump committed a cri...  \n",
       "4  Candles are placed in front of a photo of cine...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11587</td>\n",
       "      <td>11586</td>\n",
       "      <td>11419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>20</td>\n",
       "      <td>716</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>politicususa</td>\n",
       "      <td>Nicolle Wallace Devastates Trump And Shows Why...</td>\n",
       "      <td>Contact Us\\nThis material may not be published...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>720</td>\n",
       "      <td>127</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              source                                              title  \\\n",
       "count          11587                                              11586   \n",
       "unique            20                                                716   \n",
       "top     politicususa  Nicolle Wallace Devastates Trump And Shows Why...   \n",
       "freq             720                                                127   \n",
       "\n",
       "                                                     text  \n",
       "count                                               11419  \n",
       "unique                                               1062  \n",
       "top     Contact Us\\nThis material may not be published...  \n",
       "freq                                                  698  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Clean, deduplicate, and tokenize the documents. You should be able to repurpose your code from the EDA assignment to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "import spacy\n",
    "import string\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings('ignore')\n",
    "NLP = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by dropping duplicates if based on source and text\n",
    "articles.drop_duplicates(subset = ['source', 'text'], inplace = True) \n",
    "\n",
    "#dropping the Na values\n",
    "articles.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cfea23c487460ca8810dcbd3cbc8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the tokens\n",
    "\n",
    "punctuation = list(string.punctuation)\n",
    "whitespace = list(string.whitespace)[1:] #want to remove the new line characters and tabs, don't want to remove all space though so take after first index\n",
    "undesired_characters = punctuation + whitespace\n",
    "articles['tokens'] = articles['text'].progress_apply(lambda x: \n",
    "                                             [x.text.lower() for x in NLP(x) if x.text.lower() not in undesired_characters]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politicususa</td>\n",
       "      <td>Prosecutors Pay Attention: Stormy Daniels Than...</td>\n",
       "      <td>Manhattan prosecutors are likely to notice tha...</td>\n",
       "      <td>[manhattan, prosecutors, are, likely, to, noti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politicususa</td>\n",
       "      <td>Investigators Push For Access To Trump Staff C...</td>\n",
       "      <td>Print\\nInvestigators looking into Donald Trump...</td>\n",
       "      <td>[print, investigators, looking, into, donald, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politicususa</td>\n",
       "      <td>The End Is Near For George Santos As He Steps ...</td>\n",
       "      <td>The AP reported:\\nRepublican Rep. George Santo...</td>\n",
       "      <td>[the, ap, reported, republican, rep., george, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politicususa</td>\n",
       "      <td>Rachel Maddow Cuts Trump To The Bone With Stor...</td>\n",
       "      <td>Rachel Maddow showed how Trump committed a cri...</td>\n",
       "      <td>[rachel, maddow, showed, how, trump, committed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vox</td>\n",
       "      <td>Alec Baldwin has been formally charged with in...</td>\n",
       "      <td>Candles are placed in front of a photo of cine...</td>\n",
       "      <td>[candles, are, placed, in, front, of, a, photo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         source                                              title  \\\n",
       "0  politicususa  Prosecutors Pay Attention: Stormy Daniels Than...   \n",
       "1  politicususa  Investigators Push For Access To Trump Staff C...   \n",
       "2  politicususa  The End Is Near For George Santos As He Steps ...   \n",
       "3  politicususa  Rachel Maddow Cuts Trump To The Bone With Stor...   \n",
       "4           vox  Alec Baldwin has been formally charged with in...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Manhattan prosecutors are likely to notice tha...   \n",
       "1  Print\\nInvestigators looking into Donald Trump...   \n",
       "2  The AP reported:\\nRepublican Rep. George Santo...   \n",
       "3  Rachel Maddow showed how Trump committed a cri...   \n",
       "4  Candles are placed in front of a photo of cine...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [manhattan, prosecutors, are, likely, to, noti...  \n",
       "1  [print, investigators, looking, into, donald, ...  \n",
       "2  [the, ap, reported, republican, rep., george, ...  \n",
       "3  [rachel, maddow, showed, how, trump, committed...  \n",
       "4  [candles, are, placed, in, front, of, a, photo...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each article is now tockenized\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "\n",
    "Load the pre-trained word embedding model. You can use the code provided in the lecture notebooks to load the model. Vectorize the documents using the pre-trained word embedding model. You can do this by averaging the vectors of the individual words in each document or using a more sophisticated technique such as doc2vec (see SpaCy and Gensim packages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "# start by loading the gensim pretrained model\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import gensim.downloader\n",
    "from gensim import similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the pretrained model\n",
    "model = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will try to just do the average of the vectors for the words. When I looked into the doc2vec method, the only resources I could\n",
    "# find showed training a new model. None of the examples had using a pre-trained embedding.\n",
    "\n",
    "# Iterate through each word in each document, then average the vectors to get the document vector representation\n",
    "\n",
    "# a list to hold the vector representations of each document\n",
    "document_vectors = [] \n",
    "\n",
    "# iterating through each article in the series by index\n",
    "for i in list(articles['tokens'].index): \n",
    "    \n",
    "    # selecting the document\n",
    "    document = articles['tokens'][i] \n",
    "    \n",
    "    # a list to hold the vectors for each word in the document\n",
    "    document_word_vectors = [] \n",
    "    for word in document:\n",
    "        # using try because of emojis which are not in the pre-trained embeddings\n",
    "        try: \n",
    "            #getting the vector representation of the word based on the model's embeddings\n",
    "            word_vector = model.get_vector(word) \n",
    "            #appending the embeddings to the list\n",
    "            document_word_vectors.append(word_vector)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    #averaging the word vectors for the document to get a single vector\n",
    "    document_vector = sum(document_word_vectors) / len(document_word_vectors) \n",
    "    document_vectors.append(document_vector)\n",
    "\n",
    "# now I have the document vectors, can add them as a column to the table\n",
    "articles['embedding_vectors'] = document_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search engine\n",
    "\n",
    "Write a search engine that can retrieve documents related to a given query based on semantic similarity. Given a query, map it to a vector using the same technique you used for the documents. Then, retrieve the documents that are most similar to the query vector based on cosine similarity or another distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "# function to tokenize the querry and returns its vector form\n",
    "\n",
    "def transform_query(query):\n",
    "    NLP = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    punctuation = list(string.punctuation)\n",
    "    whitespace = list(string.whitespace)[1:]\n",
    "    undesired_characters = punctuation + whitespace\n",
    "    \n",
    "    #tokenization that I used previously\n",
    "    document = [x.text.lower() for x in NLP(query) if x.text.lower() not in undesired_characters] \n",
    "    \n",
    "    # a list to hold the vectors for each word in the document\n",
    "    document_word_vectors = [] \n",
    "    for word in document:\n",
    "        try:\n",
    "            word_vector = model.get_vector(word)\n",
    "            document_word_vectors.append(word_vector)\n",
    "        except:\n",
    "            continue\n",
    "    query_vector = sum(document_word_vectors) / len(document_word_vectors)\n",
    "    \n",
    "    return query_vector\n",
    "\n",
    "def getSimilarArticles(query):\n",
    "    \n",
    "    #transforming the query to an embedding vector\n",
    "    query_vector = transform_query(query) \n",
    "    \n",
    "    #dictionary for the similiarity scores\n",
    "    similarity_scores = {} \n",
    "    \n",
    "    #going through each corpus vector\n",
    "    for i in list(articles['embedding_vectors'].index): \n",
    "        corpus_vector = articles['embedding_vectors'][i]\n",
    "        \n",
    "        #finding the cosine distance, subtracting it from one since the smaller distnaces will mean more simliary\n",
    "        similarity = 1 - spatial.distance.cosine(query_vector, corpus_vector) \n",
    "        similarity_scores[i] = similarity \n",
    "        \n",
    "    #sort the dictionary based on the similarity scores in descending order, select the top 10\n",
    "    top_ten = sorted(similarity_scores.items(), key = operator.itemgetter(1), reverse = True)[:10] \n",
    "    top_ten_indicies = [i[0] for i in top_ten]\n",
    "    \n",
    "    #return the top 10 article results in a data frame format\n",
    "    return articles.loc[top_ten_indicies][['source', 'title', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm takes in a query and transforms it. This transformation starts with tokenization in the same way that I tokenized the documents in the corpus. Next, each token in the query is transformed into its embedding vector using the pre-trained model. The embedding vector for each word in the query is averaged together give one vector for the whole query. Once the query is vectorized, the algorithm calculates the cosine distance of its vector from each document vector. These results are saved in a dictionary which is sorted in descending order. The top 10 results are retrieved and their indices are used to pull their rows of the dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Examples of Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>msnbc</td>\n",
       "      <td>Video released of Trump deposition in New York...</td>\n",
       "      <td>Video released of Trump deposition in NY fraud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9161</th>\n",
       "      <td>abcnews.go</td>\n",
       "      <td>Top Trump Organization executive to appear bef...</td>\n",
       "      <td>Top Trump Organization executive to appear bef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10225</th>\n",
       "      <td>thehill</td>\n",
       "      <td>Trump Organization controller expected to appe...</td>\n",
       "      <td>Email\\nAssociated Press/Seth Wenig\\nA Trump Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8531</th>\n",
       "      <td>thehill</td>\n",
       "      <td>Cohen says he turned over cellphones to Manhat...</td>\n",
       "      <td>Cohen says he turned over cellphones to Manhat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8408</th>\n",
       "      <td>thehill</td>\n",
       "      <td>Cohen says he turned over cell phones to Manha...</td>\n",
       "      <td>Cohen says he turned over cell phones to Manha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>vox</td>\n",
       "      <td>Donald Trump could be criminally charged in th...</td>\n",
       "      <td>President Donald Trump greets people at a New ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politicususa</td>\n",
       "      <td>Prosecutors Pay Attention: Stormy Daniels Than...</td>\n",
       "      <td>Manhattan prosecutors are likely to notice tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8969</th>\n",
       "      <td>thegatewaypundit</td>\n",
       "      <td>Liberal Columbia Journalism Review Issues Scat...</td>\n",
       "      <td>ShareShareShare Email\\nSEVEN YEARS after the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>thehill</td>\n",
       "      <td>Ethics concerns raised over business ties of S...</td>\n",
       "      <td>Ethics concerns raised over business ties of S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>westernjournal</td>\n",
       "      <td>'RINO GLOBALIST': Donald Trump Goes Scorched E...</td>\n",
       "      <td>'RINO GLOBALIST': Donald Trump Goes Scorched E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 source                                              title  \\\n",
       "5708              msnbc  Video released of Trump deposition in New York...   \n",
       "9161         abcnews.go  Top Trump Organization executive to appear bef...   \n",
       "10225           thehill  Trump Organization controller expected to appe...   \n",
       "8531            thehill  Cohen says he turned over cellphones to Manhat...   \n",
       "8408            thehill  Cohen says he turned over cell phones to Manha...   \n",
       "65                  vox  Donald Trump could be criminally charged in th...   \n",
       "0          politicususa  Prosecutors Pay Attention: Stormy Daniels Than...   \n",
       "8969   thegatewaypundit  Liberal Columbia Journalism Review Issues Scat...   \n",
       "1552            thehill  Ethics concerns raised over business ties of S...   \n",
       "10205    westernjournal  'RINO GLOBALIST': Donald Trump Goes Scorched E...   \n",
       "\n",
       "                                                    text  \n",
       "5708   Video released of Trump deposition in NY fraud...  \n",
       "9161   Top Trump Organization executive to appear bef...  \n",
       "10225  Email\\nAssociated Press/Seth Wenig\\nA Trump Or...  \n",
       "8531   Cohen says he turned over cellphones to Manhat...  \n",
       "8408   Cohen says he turned over cell phones to Manha...  \n",
       "65     President Donald Trump greets people at a New ...  \n",
       "0      Manhattan prosecutors are likely to notice tha...  \n",
       "8969   ShareShareShare Email\\nSEVEN YEARS after the l...  \n",
       "1552   Ethics concerns raised over business ties of S...  \n",
       "10205  'RINO GLOBALIST': Donald Trump Goes Scorched E...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first pull the title of the first document\n",
    "query = articles['title'][0]\n",
    "\n",
    "results = getSimilarArticles(query)\n",
    "results\n",
    "\n",
    "#the correct article was given as the 7th top result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7903</th>\n",
       "      <td>dailycaller</td>\n",
       "      <td>‘We Were Really Dedicated’: Arian Foster, Marl...</td>\n",
       "      <td>February 01, 2023 10:36 AM ET\\nFont Size:\\nI w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6892</th>\n",
       "      <td>westernjournal</td>\n",
       "      <td>CNN Calls in Bill Maher, But It Most Likely Wo...</td>\n",
       "      <td>Commentary\\nCommentary\\nHBO comedian Bill Mahe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7427</th>\n",
       "      <td>westernjournal</td>\n",
       "      <td>CNN Calls in Bill Maher, But It Most Likely Wo...</td>\n",
       "      <td>Commentary\\nCommentary\\nHBO comedian Bill Mahe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vox</td>\n",
       "      <td>Sundance 2023: 17 movies to watch out for this...</td>\n",
       "      <td>Chiwetel Ejiofor and Emilia Clarke in The Pod ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7428</th>\n",
       "      <td>westernjournal</td>\n",
       "      <td>Tom Brady Announces He's Retiring 'For Good' i...</td>\n",
       "      <td>NFL quarterback Tom Brady, a cast member and p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9732</th>\n",
       "      <td>westernjournal</td>\n",
       "      <td>Tim Allen Says Pamela Anderson Has a 'Weird Me...</td>\n",
       "      <td>Tim Allen poses for a portrait at the 43rd Ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>westernjournal</td>\n",
       "      <td>Tim Allen Says Pamela Anderson Has a 'Weird Me...</td>\n",
       "      <td>Tim Allen poses for a portrait at the 43rd Ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9811</th>\n",
       "      <td>westernjournal</td>\n",
       "      <td>Tim Allen Says Pamela Anderson Has a 'Weird Me...</td>\n",
       "      <td>Tim Allen poses for a portrait at the 43rd Ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>thehill</td>\n",
       "      <td>Jon Stewart blasts media for playing Tyre Nich...</td>\n",
       "      <td>Jon Stewart blasts media for playing Tyre Nich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>thehill</td>\n",
       "      <td>'Dr. Phil' to end after 21 seasons</td>\n",
       "      <td>Email\\n( NewsNation ) — TV host and celebrity ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              source                                              title  \\\n",
       "7903     dailycaller  ‘We Were Really Dedicated’: Arian Foster, Marl...   \n",
       "6892  westernjournal  CNN Calls in Bill Maher, But It Most Likely Wo...   \n",
       "7427  westernjournal  CNN Calls in Bill Maher, But It Most Likely Wo...   \n",
       "7                vox  Sundance 2023: 17 movies to watch out for this...   \n",
       "7428  westernjournal  Tom Brady Announces He's Retiring 'For Good' i...   \n",
       "9732  westernjournal  Tim Allen Says Pamela Anderson Has a 'Weird Me...   \n",
       "9892  westernjournal  Tim Allen Says Pamela Anderson Has a 'Weird Me...   \n",
       "9811  westernjournal  Tim Allen Says Pamela Anderson Has a 'Weird Me...   \n",
       "9560         thehill  Jon Stewart blasts media for playing Tyre Nich...   \n",
       "5731         thehill                 'Dr. Phil' to end after 21 seasons   \n",
       "\n",
       "                                                   text  \n",
       "7903  February 01, 2023 10:36 AM ET\\nFont Size:\\nI w...  \n",
       "6892  Commentary\\nCommentary\\nHBO comedian Bill Mahe...  \n",
       "7427  Commentary\\nCommentary\\nHBO comedian Bill Mahe...  \n",
       "7     Chiwetel Ejiofor and Emilia Clarke in The Pod ...  \n",
       "7428  NFL quarterback Tom Brady, a cast member and p...  \n",
       "9732  Tim Allen poses for a portrait at the 43rd Ann...  \n",
       "9892  Tim Allen poses for a portrait at the 43rd Ann...  \n",
       "9811  Tim Allen poses for a portrait at the 43rd Ann...  \n",
       "9560  Jon Stewart blasts media for playing Tyre Nich...  \n",
       "5731  Email\\n( NewsNation ) — TV host and celebrity ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try the title of the 7th index\n",
    "query = articles['title'][7]\n",
    "\n",
    "results = getSimilarArticles(query)\n",
    "results\n",
    "# gives it as the 4th result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8428</th>\n",
       "      <td>msnbc</td>\n",
       "      <td>FBI searches President Biden's Rehoboth home</td>\n",
       "      <td>Rev. Al: We will stand and fight in the name o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8905</th>\n",
       "      <td>msnbc</td>\n",
       "      <td>FBI searches President Biden's Rehoboth home</td>\n",
       "      <td>Rev. Al: We will stand and fight in the name o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>msnbc</td>\n",
       "      <td>Video released of Trump deposition in New York...</td>\n",
       "      <td>Video released of Trump deposition in NY fraud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6110</th>\n",
       "      <td>msnbc</td>\n",
       "      <td>Lawrence: Tyre Nichols' family, civil rights l...</td>\n",
       "      <td>Sen. Murphy: ‘Don’t negotiate’ with House GOP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7867</th>\n",
       "      <td>msnbc</td>\n",
       "      <td>FBI searches President Biden's Rehoboth home</td>\n",
       "      <td>Rev. Al: We will stand and fight in the name o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>msnbc</td>\n",
       "      <td>Lawrence: Tyre Nichols’ family spoke in the sa...</td>\n",
       "      <td>Sen. Murphy: ‘Don’t negotiate’ with House GOP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7307</th>\n",
       "      <td>msnbc</td>\n",
       "      <td>FBI searches President Biden's Rehoboth home</td>\n",
       "      <td>Rev. Al: We will stand and fight in the name o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>westernjournal</td>\n",
       "      <td>'RINO GLOBALIST': Donald Trump Goes Scorched E...</td>\n",
       "      <td>Florida Gov.-elect Ron DeSantis sits next to P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7704</th>\n",
       "      <td>huffpost</td>\n",
       "      <td>Ron DeSantis Dismisses Trump's Criticism Of Hi...</td>\n",
       "      <td>Politics Donald Trump Ron DeSantis\\nRon DeSant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7627</th>\n",
       "      <td>msnbc</td>\n",
       "      <td>FBI searches President Biden's Rehoboth home</td>\n",
       "      <td>Rev. Al: We will stand and fight in the name o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              source                                              title  \\\n",
       "8428           msnbc       FBI searches President Biden's Rehoboth home   \n",
       "8905           msnbc       FBI searches President Biden's Rehoboth home   \n",
       "5708           msnbc  Video released of Trump deposition in New York...   \n",
       "6110           msnbc  Lawrence: Tyre Nichols' family, civil rights l...   \n",
       "7867           msnbc       FBI searches President Biden's Rehoboth home   \n",
       "7390           msnbc  Lawrence: Tyre Nichols’ family spoke in the sa...   \n",
       "7307           msnbc       FBI searches President Biden's Rehoboth home   \n",
       "9890  westernjournal  'RINO GLOBALIST': Donald Trump Goes Scorched E...   \n",
       "7704        huffpost  Ron DeSantis Dismisses Trump's Criticism Of Hi...   \n",
       "7627           msnbc       FBI searches President Biden's Rehoboth home   \n",
       "\n",
       "                                                   text  \n",
       "8428  Rev. Al: We will stand and fight in the name o...  \n",
       "8905  Rev. Al: We will stand and fight in the name o...  \n",
       "5708  Video released of Trump deposition in NY fraud...  \n",
       "6110  Sen. Murphy: ‘Don’t negotiate’ with House GOP ...  \n",
       "7867  Rev. Al: We will stand and fight in the name o...  \n",
       "7390  Sen. Murphy: ‘Don’t negotiate’ with House GOP ...  \n",
       "7307  Rev. Al: We will stand and fight in the name o...  \n",
       "9890  Florida Gov.-elect Ron DeSantis sits next to P...  \n",
       "7704  Politics Donald Trump Ron DeSantis\\nRon DeSant...  \n",
       "7627  Rev. Al: We will stand and fight in the name o...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a query that is not a title\n",
    "\n",
    "results = getSimilarArticles('Donald Trump White House')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are duplicates in the results even though I dropped the duplicates based on the source and text. The reason could be that the text varies by a small amount but I am not entirely sure so I will test with these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shows that the text are different somehow so they're not duplicates in the results\n",
    "results['text'][8428] == results['text'][8905] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra credit\n",
    "\n",
    "Based on the results of your search engine, write a kmeans clustering algorithm that can cluster the documents into groups based on their semantic similarity, along with some topics words that can describe each cluster. Some tips are to look into kmeans++, DBSCAN, and agglomerative clustering. For example, see this blog post: https://towardsdatascience.com/silhouette-method-better-than-elbow-method-to-find-optimal-clusters-378d62ff6891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
